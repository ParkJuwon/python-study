{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n여러가지 가짜 이미지를 생성하는 생성자, 진짜 이미지와 가짜 이미지를 구분하는 판별자 존재\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "GAN (generative adversarial network) : 적대적 생성 신경망\n",
    "GAN은 생성하는 모델\n",
    "GAN은 적대적으로 학습 - 가짜 이미지를 생성하는 생성자와 이미지의 진위를 판별하는 판별자\n",
    "GAN은 인공 신경망 모델 - 생성자, 판별자 모두 신경망\n",
    "비지도 학습\n",
    "'''\n",
    "\n",
    "'''\n",
    "여러가지 가짜 이미지를 생성하는 생성자, 진짜 이미지와 가짜 이미지를 구분하는 판별자 존재\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 장치를 사용합니다 :  cpu\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 장치를 사용합니다 : \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26427392it [01:10, 1446848.32it/s]                              "
     ]
    }
   ],
   "source": [
    "# Fashine MNIST 데이터셋\n",
    "trainset = datasets.FashionMNIST('./data',\n",
    "                                train=True,\n",
    "                                download=True,\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,))\n",
    "                                ]))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                dataset = trainset,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanh 활성화 함수는 결괏값을 -1, 1사이로 압축하는 역할\n",
    "# 무작위 텐서를 입력하는 이유는 생성자가 실제 데이터의 분포를 배우는 것이기 때문\n",
    "\n",
    "# 생성자 (Generator)\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(64, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 784),\n",
    "    nn.Tanh()\n",
    ")\n",
    "\n",
    "# 판별자 (Discriminator)\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 가중치를 지정한 장치로 보내기\n",
    "D = D.to(DEVICE)\n",
    "G = G.to(DEVICE)\n",
    "\n",
    "# 이진 교차 엔트로피 오차 함수와\n",
    "# 생성자와 판별자를 최적화할 Adam 모듈\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [0/500] d_loss:0.0227 g_loss:5.6821 D(x):1.00 D(G(z)):0.02\n",
      "이폭 [1/500] d_loss:0.0268 g_loss:11.1073 D(x):0.99 D(G(z)):0.00\n",
      "이폭 [2/500] d_loss:0.0387 g_loss:6.1597 D(x):0.99 D(G(z)):0.01\n",
      "이폭 [3/500] d_loss:0.3628 g_loss:4.9568 D(x):0.89 D(G(z)):0.03\n",
      "이폭 [4/500] d_loss:0.0641 g_loss:7.0832 D(x):0.97 D(G(z)):0.00\n",
      "이폭 [5/500] d_loss:0.0808 g_loss:7.1467 D(x):0.98 D(G(z)):0.02\n",
      "이폭 [6/500] d_loss:0.1067 g_loss:5.8809 D(x):0.96 D(G(z)):0.02\n",
      "이폭 [7/500] d_loss:0.1559 g_loss:4.8728 D(x):0.95 D(G(z)):0.03\n",
      "이폭 [8/500] d_loss:0.0735 g_loss:8.2212 D(x):0.97 D(G(z)):0.01\n",
      "이폭 [9/500] d_loss:0.3304 g_loss:3.4643 D(x):0.93 D(G(z)):0.11\n",
      "이폭 [10/500] d_loss:0.1598 g_loss:5.5439 D(x):0.95 D(G(z)):0.02\n",
      "이폭 [11/500] d_loss:0.2470 g_loss:4.7903 D(x):0.92 D(G(z)):0.03\n",
      "이폭 [12/500] d_loss:0.3400 g_loss:3.7512 D(x):0.94 D(G(z)):0.16\n",
      "이폭 [13/500] d_loss:0.2231 g_loss:4.4818 D(x):0.93 D(G(z)):0.08\n",
      "이폭 [14/500] d_loss:0.3378 g_loss:4.8997 D(x):0.90 D(G(z)):0.08\n",
      "이폭 [15/500] d_loss:0.2534 g_loss:4.4047 D(x):0.96 D(G(z)):0.11\n",
      "이폭 [16/500] d_loss:0.3886 g_loss:3.7496 D(x):0.95 D(G(z)):0.20\n",
      "이폭 [17/500] d_loss:0.3999 g_loss:4.0468 D(x):0.89 D(G(z)):0.09\n",
      "이폭 [18/500] d_loss:0.4900 g_loss:4.6813 D(x):0.84 D(G(z)):0.10\n",
      "이폭 [19/500] d_loss:0.3589 g_loss:3.5109 D(x):0.88 D(G(z)):0.11\n",
      "이폭 [20/500] d_loss:0.4504 g_loss:3.4005 D(x):0.93 D(G(z)):0.14\n",
      "이폭 [21/500] d_loss:0.4674 g_loss:3.3232 D(x):0.87 D(G(z)):0.15\n",
      "이폭 [22/500] d_loss:0.3760 g_loss:3.5603 D(x):0.87 D(G(z)):0.10\n",
      "이폭 [23/500] d_loss:0.4695 g_loss:3.9056 D(x):0.86 D(G(z)):0.11\n",
      "이폭 [24/500] d_loss:0.3086 g_loss:3.5653 D(x):0.88 D(G(z)):0.05\n",
      "이폭 [25/500] d_loss:0.5037 g_loss:2.5689 D(x):0.89 D(G(z)):0.23\n",
      "이폭 [26/500] d_loss:0.3607 g_loss:3.5904 D(x):0.88 D(G(z)):0.11\n",
      "이폭 [27/500] d_loss:0.4734 g_loss:3.4490 D(x):0.90 D(G(z)):0.17\n",
      "이폭 [28/500] d_loss:0.4864 g_loss:2.2432 D(x):0.89 D(G(z)):0.21\n",
      "이폭 [29/500] d_loss:0.7561 g_loss:3.0359 D(x):0.78 D(G(z)):0.18\n",
      "이폭 [30/500] d_loss:0.5397 g_loss:2.3200 D(x):0.87 D(G(z)):0.22\n",
      "이폭 [31/500] d_loss:0.5482 g_loss:2.4436 D(x):0.87 D(G(z)):0.23\n",
      "이폭 [32/500] d_loss:0.4537 g_loss:3.2504 D(x):0.86 D(G(z)):0.14\n",
      "이폭 [33/500] d_loss:0.7486 g_loss:2.8622 D(x):0.86 D(G(z)):0.23\n",
      "이폭 [34/500] d_loss:0.5323 g_loss:2.3422 D(x):0.85 D(G(z)):0.19\n",
      "이폭 [35/500] d_loss:0.5870 g_loss:2.4352 D(x):0.81 D(G(z)):0.16\n",
      "이폭 [36/500] d_loss:0.5129 g_loss:2.8498 D(x):0.86 D(G(z)):0.19\n",
      "이폭 [37/500] d_loss:0.4389 g_loss:4.1767 D(x):0.86 D(G(z)):0.12\n",
      "이폭 [38/500] d_loss:0.6908 g_loss:2.6426 D(x):0.80 D(G(z)):0.18\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        # 진짜와 가짜 레이블 생성\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "        \n",
    "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차 계산\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # 무작위 텐서로 가짜 이미지 생성\n",
    "        z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # 판별자가 가짜 이미지를 가짜로 인식하는 오차 계산\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # 진짜와 가짜 이미지를 갖고 낸 오차를 더해서 판별자의 오차 계산\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        # 역전파 알고리즘으로 판별자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 생성자가 판별자를 속였는지에 대한 오차 계산\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # 역전파 알고리즘으로 생성자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    # 학습 진행 알아보기\n",
    "    print('이폭 [{}/{}] d_loss:{:.4f} g_loss:{:.4f} D(x):{:.2f} D(G(z)):{:.2f}'\n",
    "          .format(epoch, EPOCHS, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))\n",
    "\n",
    "# 생성자가 만든 이미지 시각화 하기\n",
    "z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "fake_images = G(z)\n",
    "for i in range(10):\n",
    "    fake_images_img = np.reshape(fake_images.data.cpu().numpy()[i], (28, 28))\n",
    "    plt.imshow(fake_images_img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 (Generator)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "                    nn.Linear(110, 256),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    nn.Linear(256, 512),\n",
    "                    nn.LeakyReLU(0.2, inpalce=True),\n",
    "                    nn.Linear(512, 1024),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    nn.Linear(1024, 784),\n",
    "                    nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([z,c], 1)\n",
    "        return self.model(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 (Discriminator)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
