{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "- convolutional neural network\n",
    "- 합성곱 신경망\n",
    "- 이미지나 비디오 같은 영상 인식에 특화된 설계\n",
    "- 병렬 처리가 쉽다\n",
    "- 최근 이미지뿐 아니라 자연어 처리와 추천 시스템에 응용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션\n",
    "- 사람은 이미지를 보는 순간 이미지 속의 계층적인 특성을 곧바로 인식\n",
    "- 컨볼루션의 목적은 계층적으로 인식할 수 있도록 단계마다 이미지의 특징을 추출\n",
    "- 필터를 적용할때 이미지 왼쪽 위에서 오른쪽 밑까지 밀어가며 곱하고 더하는데 이작업을 '컨볼루션' 이라고 함\n",
    "- CNN은 이미지를 추출하는 필터를 학습\n",
    "- 필터가 하나의 작은 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델\n",
    "- 컨볼루션 계층, 풀링 계층, 특징들을 모아 최종 분류하는 일반적인 인공 신경망 계층으로 구성\n",
    "- 컨볼루션 계층은 이미지의 특징을 추출하는 역할\n",
    "- 풀링 계층은 필터를 거친 여러 특징 중 가장 중요한 특징 하나를 골라냄\n",
    "- 덜 중요한 특징을 버리기 때문에 이미지의 차원이 감소\n",
    "- 풀고자 하는 문제에 따라 계층 구성을 달리 할 수 있음\n",
    "- 컨볼루션 계층으로만 구성된 모델을 만들 수 있음\n",
    "- 컨볼루션 연산은 이미지를 겹치는 매우 작은 조각으로 쪼개어 필터 기능을 하는 작은 신경망에 적용\n",
    "- 신경망은 모든 조각에 동일하게 적용되며 특징을 추출하기 때문에 컨볼루션 필터, 커널이라고 부름\n",
    "- 커널은 컨볼루션 계층 하나에 여러개가 존재할 수 있음\n",
    "- 보통 3x3, 5x5 크기의 커널이 쓰임\n",
    "- 학습 시 필터 행렬의 값은 특징을 잘 뽑을 수 있도록 최적화\n",
    "- 움직이는 칸을 조절하는 값을 스트라이드(stride)라고 함\n",
    "    - 스트라이드를 올려 여러칸을 건너 뛸수록 출력되는 텐서가 크기가 작아짐\n",
    "- 컨볼루션을 거쳐 만들어진 새로운 이미지는 특징 맵이라고 부름\n",
    "- 컨볼루션 계층마다 여러 특징 맵이 만들어지며, 다음 단계인 풀링 계층으로 넘어감\n",
    "- 특징 맵의 크기가 크면 학습이 어렵고 과적합 위험이 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델 구현하기\n",
    "- 컨볼루션, 풀링, 드롭아웃, 그리고 일반적인 신경망 계층의 조합으로 이루어짐\n",
    "- 예제에선 [컨볼루선 -> 풀링 -> 컨볼루션 -> 드롭아웃 -> 풀링 -> 신경망 -> 드롭아웃 -> 신경망] 식으로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%\tLoss:2.324538)]\n",
      "Train Epoch: 1 [12800/60000 (21%\tLoss:1.306861)]\n",
      "Train Epoch: 1 [25600/60000 (43%\tLoss:0.783383)]\n",
      "Train Epoch: 1 [38400/60000 (64%\tLoss:0.805570)]\n",
      "Train Epoch: 1 [51200/60000 (85%\tLoss:0.845462)]\n",
      "[1] Test Loss: 0.6151, Accuracy: 75.61%\n",
      "Train Epoch: 2 [0/60000 (0%\tLoss:0.655264)]\n",
      "Train Epoch: 2 [12800/60000 (21%\tLoss:0.688394)]\n",
      "Train Epoch: 2 [25600/60000 (43%\tLoss:0.438884)]\n",
      "Train Epoch: 2 [38400/60000 (64%\tLoss:0.694537)]\n",
      "Train Epoch: 2 [51200/60000 (85%\tLoss:0.606960)]\n",
      "[2] Test Loss: 0.5422, Accuracy: 78.32%\n",
      "Train Epoch: 3 [0/60000 (0%\tLoss:0.561760)]\n",
      "Train Epoch: 3 [12800/60000 (21%\tLoss:0.617927)]\n",
      "Train Epoch: 3 [25600/60000 (43%\tLoss:0.636660)]\n",
      "Train Epoch: 3 [38400/60000 (64%\tLoss:0.561378)]\n",
      "Train Epoch: 3 [51200/60000 (85%\tLoss:0.673515)]\n",
      "[3] Test Loss: 0.5028, Accuracy: 80.35%\n",
      "Train Epoch: 4 [0/60000 (0%\tLoss:0.759757)]\n",
      "Train Epoch: 4 [12800/60000 (21%\tLoss:0.753279)]\n",
      "Train Epoch: 4 [25600/60000 (43%\tLoss:0.655037)]\n",
      "Train Epoch: 4 [38400/60000 (64%\tLoss:0.572039)]\n",
      "Train Epoch: 4 [51200/60000 (85%\tLoss:0.578930)]\n",
      "[4] Test Loss: 0.4760, Accuracy: 82.75%\n",
      "Train Epoch: 5 [0/60000 (0%\tLoss:0.516586)]\n",
      "Train Epoch: 5 [12800/60000 (21%\tLoss:0.581746)]\n",
      "Train Epoch: 5 [25600/60000 (43%\tLoss:0.674359)]\n",
      "Train Epoch: 5 [38400/60000 (64%\tLoss:0.512461)]\n",
      "Train Epoch: 5 [51200/60000 (85%\tLoss:0.479590)]\n",
      "[5] Test Loss: 0.4491, Accuracy: 83.87%\n",
      "Train Epoch: 6 [0/60000 (0%\tLoss:0.390170)]\n",
      "Train Epoch: 6 [12800/60000 (21%\tLoss:0.463371)]\n",
      "Train Epoch: 6 [25600/60000 (43%\tLoss:0.705979)]\n",
      "Train Epoch: 6 [38400/60000 (64%\tLoss:0.611604)]\n",
      "Train Epoch: 6 [51200/60000 (85%\tLoss:0.655869)]\n",
      "[6] Test Loss: 0.4074, Accuracy: 85.31%\n",
      "Train Epoch: 7 [0/60000 (0%\tLoss:0.384314)]\n",
      "Train Epoch: 7 [12800/60000 (21%\tLoss:0.430824)]\n",
      "Train Epoch: 7 [25600/60000 (43%\tLoss:0.559046)]\n",
      "Train Epoch: 7 [38400/60000 (64%\tLoss:0.393818)]\n",
      "Train Epoch: 7 [51200/60000 (85%\tLoss:0.224222)]\n",
      "[7] Test Loss: 0.3873, Accuracy: 85.90%\n",
      "Train Epoch: 8 [0/60000 (0%\tLoss:0.442850)]\n",
      "Train Epoch: 8 [12800/60000 (21%\tLoss:0.396984)]\n",
      "Train Epoch: 8 [25600/60000 (43%\tLoss:0.339614)]\n",
      "Train Epoch: 8 [38400/60000 (64%\tLoss:0.425395)]\n",
      "Train Epoch: 8 [51200/60000 (85%\tLoss:0.385684)]\n",
      "[8] Test Loss: 0.3763, Accuracy: 86.22%\n",
      "Train Epoch: 9 [0/60000 (0%\tLoss:0.477719)]\n",
      "Train Epoch: 9 [12800/60000 (21%\tLoss:0.557010)]\n",
      "Train Epoch: 9 [25600/60000 (43%\tLoss:0.309025)]\n",
      "Train Epoch: 9 [38400/60000 (64%\tLoss:0.511984)]\n",
      "Train Epoch: 9 [51200/60000 (85%\tLoss:0.399507)]\n",
      "[9] Test Loss: 0.3668, Accuracy: 86.54%\n",
      "Train Epoch: 10 [0/60000 (0%\tLoss:0.312758)]\n",
      "Train Epoch: 10 [12800/60000 (21%\tLoss:0.436128)]\n",
      "Train Epoch: 10 [25600/60000 (43%\tLoss:0.490449)]\n",
      "Train Epoch: 10 [38400/60000 (64%\tLoss:0.539662)]\n",
      "Train Epoch: 10 [51200/60000 (85%\tLoss:0.398681)]\n",
      "[10] Test Loss: 0.3610, Accuracy: 87.02%\n",
      "Train Epoch: 11 [0/60000 (0%\tLoss:0.521238)]\n",
      "Train Epoch: 11 [12800/60000 (21%\tLoss:0.481218)]\n",
      "Train Epoch: 11 [25600/60000 (43%\tLoss:0.390267)]\n",
      "Train Epoch: 11 [38400/60000 (64%\tLoss:0.302238)]\n",
      "Train Epoch: 11 [51200/60000 (85%\tLoss:0.386463)]\n",
      "[11] Test Loss: 0.3582, Accuracy: 87.06%\n",
      "Train Epoch: 12 [0/60000 (0%\tLoss:0.572518)]\n",
      "Train Epoch: 12 [12800/60000 (21%\tLoss:0.421976)]\n",
      "Train Epoch: 12 [25600/60000 (43%\tLoss:0.376691)]\n",
      "Train Epoch: 12 [38400/60000 (64%\tLoss:0.313585)]\n",
      "Train Epoch: 12 [51200/60000 (85%\tLoss:0.425306)]\n",
      "[12] Test Loss: 0.3414, Accuracy: 87.49%\n",
      "Train Epoch: 13 [0/60000 (0%\tLoss:0.499204)]\n",
      "Train Epoch: 13 [12800/60000 (21%\tLoss:0.418177)]\n",
      "Train Epoch: 13 [25600/60000 (43%\tLoss:0.341304)]\n",
      "Train Epoch: 13 [38400/60000 (64%\tLoss:0.322165)]\n",
      "Train Epoch: 13 [51200/60000 (85%\tLoss:0.547415)]\n",
      "[13] Test Loss: 0.3460, Accuracy: 87.02%\n",
      "Train Epoch: 14 [0/60000 (0%\tLoss:0.447920)]\n",
      "Train Epoch: 14 [12800/60000 (21%\tLoss:0.303148)]\n",
      "Train Epoch: 14 [25600/60000 (43%\tLoss:0.282353)]\n",
      "Train Epoch: 14 [38400/60000 (64%\tLoss:0.290839)]\n",
      "Train Epoch: 14 [51200/60000 (85%\tLoss:0.303257)]\n",
      "[14] Test Loss: 0.3343, Accuracy: 88.06%\n",
      "Train Epoch: 15 [0/60000 (0%\tLoss:0.384460)]\n",
      "Train Epoch: 15 [12800/60000 (21%\tLoss:0.400166)]\n",
      "Train Epoch: 15 [25600/60000 (43%\tLoss:0.443676)]\n",
      "Train Epoch: 15 [38400/60000 (64%\tLoss:0.376252)]\n",
      "Train Epoch: 15 [51200/60000 (85%\tLoss:0.294987)]\n",
      "[15] Test Loss: 0.3397, Accuracy: 87.15%\n",
      "Train Epoch: 16 [0/60000 (0%\tLoss:0.289382)]\n",
      "Train Epoch: 16 [12800/60000 (21%\tLoss:0.245482)]\n",
      "Train Epoch: 16 [25600/60000 (43%\tLoss:0.581534)]\n",
      "Train Epoch: 16 [38400/60000 (64%\tLoss:0.583586)]\n",
      "Train Epoch: 16 [51200/60000 (85%\tLoss:0.557144)]\n",
      "[16] Test Loss: 0.3428, Accuracy: 87.62%\n",
      "Train Epoch: 17 [0/60000 (0%\tLoss:0.488068)]\n",
      "Train Epoch: 17 [12800/60000 (21%\tLoss:0.253845)]\n",
      "Train Epoch: 17 [25600/60000 (43%\tLoss:0.391282)]\n",
      "Train Epoch: 17 [38400/60000 (64%\tLoss:0.426553)]\n",
      "Train Epoch: 17 [51200/60000 (85%\tLoss:0.262695)]\n",
      "[17] Test Loss: 0.3382, Accuracy: 87.42%\n",
      "Train Epoch: 18 [0/60000 (0%\tLoss:0.542038)]\n",
      "Train Epoch: 18 [12800/60000 (21%\tLoss:0.475057)]\n",
      "Train Epoch: 18 [25600/60000 (43%\tLoss:0.332575)]\n",
      "Train Epoch: 18 [38400/60000 (64%\tLoss:0.458191)]\n",
      "Train Epoch: 18 [51200/60000 (85%\tLoss:0.310036)]\n",
      "[18] Test Loss: 0.3267, Accuracy: 88.15%\n",
      "Train Epoch: 19 [0/60000 (0%\tLoss:0.525272)]\n",
      "Train Epoch: 19 [12800/60000 (21%\tLoss:0.364995)]\n",
      "Train Epoch: 19 [25600/60000 (43%\tLoss:0.213031)]\n",
      "Train Epoch: 19 [38400/60000 (64%\tLoss:0.392907)]\n",
      "Train Epoch: 19 [51200/60000 (85%\tLoss:0.518796)]\n",
      "[19] Test Loss: 0.3225, Accuracy: 87.83%\n",
      "Train Epoch: 20 [0/60000 (0%\tLoss:0.495267)]\n",
      "Train Epoch: 20 [12800/60000 (21%\tLoss:0.351275)]\n",
      "Train Epoch: 20 [25600/60000 (43%\tLoss:0.447986)]\n",
      "Train Epoch: 20 [38400/60000 (64%\tLoss:0.282886)]\n",
      "Train Epoch: 20 [51200/60000 (85%\tLoss:0.503494)]\n",
      "[20] Test Loss: 0.3211, Accuracy: 88.22%\n",
      "Train Epoch: 21 [0/60000 (0%\tLoss:0.283421)]\n",
      "Train Epoch: 21 [12800/60000 (21%\tLoss:0.278774)]\n",
      "Train Epoch: 21 [25600/60000 (43%\tLoss:0.393358)]\n",
      "Train Epoch: 21 [38400/60000 (64%\tLoss:0.466015)]\n",
      "Train Epoch: 21 [51200/60000 (85%\tLoss:0.349758)]\n",
      "[21] Test Loss: 0.3080, Accuracy: 88.79%\n",
      "Train Epoch: 22 [0/60000 (0%\tLoss:0.369592)]\n",
      "Train Epoch: 22 [12800/60000 (21%\tLoss:0.394510)]\n",
      "Train Epoch: 22 [25600/60000 (43%\tLoss:0.253878)]\n",
      "Train Epoch: 22 [38400/60000 (64%\tLoss:0.362426)]\n",
      "Train Epoch: 22 [51200/60000 (85%\tLoss:0.246559)]\n",
      "[22] Test Loss: 0.3110, Accuracy: 89.01%\n",
      "Train Epoch: 23 [0/60000 (0%\tLoss:0.359782)]\n",
      "Train Epoch: 23 [12800/60000 (21%\tLoss:0.387636)]\n",
      "Train Epoch: 23 [25600/60000 (43%\tLoss:0.337059)]\n",
      "Train Epoch: 23 [38400/60000 (64%\tLoss:0.496684)]\n",
      "Train Epoch: 23 [51200/60000 (85%\tLoss:0.294889)]\n",
      "[23] Test Loss: 0.3096, Accuracy: 88.87%\n",
      "Train Epoch: 24 [0/60000 (0%\tLoss:0.363824)]\n",
      "Train Epoch: 24 [12800/60000 (21%\tLoss:0.266320)]\n",
      "Train Epoch: 24 [25600/60000 (43%\tLoss:0.415859)]\n",
      "Train Epoch: 24 [38400/60000 (64%\tLoss:0.409853)]\n",
      "Train Epoch: 24 [51200/60000 (85%\tLoss:0.257152)]\n",
      "[24] Test Loss: 0.3170, Accuracy: 88.56%\n",
      "Train Epoch: 25 [0/60000 (0%\tLoss:0.326078)]\n",
      "Train Epoch: 25 [12800/60000 (21%\tLoss:0.299011)]\n",
      "Train Epoch: 25 [25600/60000 (43%\tLoss:0.282465)]\n",
      "Train Epoch: 25 [38400/60000 (64%\tLoss:0.209182)]\n",
      "Train Epoch: 25 [51200/60000 (85%\tLoss:0.464434)]\n",
      "[25] Test Loss: 0.3048, Accuracy: 88.92%\n",
      "Train Epoch: 26 [0/60000 (0%\tLoss:0.378626)]\n",
      "Train Epoch: 26 [12800/60000 (21%\tLoss:0.199561)]\n",
      "Train Epoch: 26 [25600/60000 (43%\tLoss:0.319930)]\n",
      "Train Epoch: 26 [38400/60000 (64%\tLoss:0.370050)]\n",
      "Train Epoch: 26 [51200/60000 (85%\tLoss:0.321544)]\n",
      "[26] Test Loss: 0.3005, Accuracy: 89.09%\n",
      "Train Epoch: 27 [0/60000 (0%\tLoss:0.278001)]\n",
      "Train Epoch: 27 [12800/60000 (21%\tLoss:0.216069)]\n",
      "Train Epoch: 27 [25600/60000 (43%\tLoss:0.333185)]\n",
      "Train Epoch: 27 [38400/60000 (64%\tLoss:0.445027)]\n",
      "Train Epoch: 27 [51200/60000 (85%\tLoss:0.407917)]\n",
      "[27] Test Loss: 0.2980, Accuracy: 88.94%\n",
      "Train Epoch: 28 [0/60000 (0%\tLoss:0.334915)]\n",
      "Train Epoch: 28 [12800/60000 (21%\tLoss:0.253465)]\n",
      "Train Epoch: 28 [25600/60000 (43%\tLoss:0.409714)]\n",
      "Train Epoch: 28 [38400/60000 (64%\tLoss:0.201967)]\n",
      "Train Epoch: 28 [51200/60000 (85%\tLoss:0.197861)]\n",
      "[28] Test Loss: 0.3114, Accuracy: 88.84%\n",
      "Train Epoch: 29 [0/60000 (0%\tLoss:0.202932)]\n",
      "Train Epoch: 29 [12800/60000 (21%\tLoss:0.286792)]\n",
      "Train Epoch: 29 [25600/60000 (43%\tLoss:0.229908)]\n",
      "Train Epoch: 29 [38400/60000 (64%\tLoss:0.286185)]\n",
      "Train Epoch: 29 [51200/60000 (85%\tLoss:0.227666)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29] Test Loss: 0.2924, Accuracy: 89.31%\n",
      "Train Epoch: 30 [0/60000 (0%\tLoss:0.543787)]\n",
      "Train Epoch: 30 [12800/60000 (21%\tLoss:0.211153)]\n",
      "Train Epoch: 30 [25600/60000 (43%\tLoss:0.311559)]\n",
      "Train Epoch: 30 [38400/60000 (64%\tLoss:0.336125)]\n",
      "Train Epoch: 30 [51200/60000 (85%\tLoss:0.488740)]\n",
      "[30] Test Loss: 0.2985, Accuracy: 89.19%\n",
      "Train Epoch: 31 [0/60000 (0%\tLoss:0.256240)]\n",
      "Train Epoch: 31 [12800/60000 (21%\tLoss:0.281465)]\n",
      "Train Epoch: 31 [25600/60000 (43%\tLoss:0.260543)]\n",
      "Train Epoch: 31 [38400/60000 (64%\tLoss:0.169477)]\n",
      "Train Epoch: 31 [51200/60000 (85%\tLoss:0.334376)]\n",
      "[31] Test Loss: 0.3012, Accuracy: 89.28%\n",
      "Train Epoch: 32 [0/60000 (0%\tLoss:0.160435)]\n",
      "Train Epoch: 32 [12800/60000 (21%\tLoss:0.261475)]\n",
      "Train Epoch: 32 [25600/60000 (43%\tLoss:0.254912)]\n",
      "Train Epoch: 32 [38400/60000 (64%\tLoss:0.371524)]\n",
      "Train Epoch: 32 [51200/60000 (85%\tLoss:0.263428)]\n",
      "[32] Test Loss: 0.3112, Accuracy: 89.19%\n",
      "Train Epoch: 33 [0/60000 (0%\tLoss:0.208024)]\n",
      "Train Epoch: 33 [12800/60000 (21%\tLoss:0.204040)]\n",
      "Train Epoch: 33 [25600/60000 (43%\tLoss:0.154154)]\n",
      "Train Epoch: 33 [38400/60000 (64%\tLoss:0.249284)]\n",
      "Train Epoch: 33 [51200/60000 (85%\tLoss:0.161783)]\n",
      "[33] Test Loss: 0.2946, Accuracy: 89.56%\n",
      "Train Epoch: 34 [0/60000 (0%\tLoss:0.277522)]\n",
      "Train Epoch: 34 [12800/60000 (21%\tLoss:0.203775)]\n",
      "Train Epoch: 34 [25600/60000 (43%\tLoss:0.297112)]\n",
      "Train Epoch: 34 [38400/60000 (64%\tLoss:0.157552)]\n",
      "Train Epoch: 34 [51200/60000 (85%\tLoss:0.338952)]\n",
      "[34] Test Loss: 0.2950, Accuracy: 89.30%\n",
      "Train Epoch: 35 [0/60000 (0%\tLoss:0.225305)]\n",
      "Train Epoch: 35 [12800/60000 (21%\tLoss:0.143647)]\n",
      "Train Epoch: 35 [25600/60000 (43%\tLoss:0.354212)]\n",
      "Train Epoch: 35 [38400/60000 (64%\tLoss:0.413304)]\n",
      "Train Epoch: 35 [51200/60000 (85%\tLoss:0.482634)]\n",
      "[35] Test Loss: 0.2930, Accuracy: 89.37%\n",
      "Train Epoch: 36 [0/60000 (0%\tLoss:0.407130)]\n",
      "Train Epoch: 36 [12800/60000 (21%\tLoss:0.309136)]\n",
      "Train Epoch: 36 [25600/60000 (43%\tLoss:0.531229)]\n",
      "Train Epoch: 36 [38400/60000 (64%\tLoss:0.244175)]\n",
      "Train Epoch: 36 [51200/60000 (85%\tLoss:0.232011)]\n",
      "[36] Test Loss: 0.2904, Accuracy: 89.45%\n",
      "Train Epoch: 37 [0/60000 (0%\tLoss:0.240826)]\n",
      "Train Epoch: 37 [12800/60000 (21%\tLoss:0.271183)]\n",
      "Train Epoch: 37 [25600/60000 (43%\tLoss:0.319698)]\n",
      "Train Epoch: 37 [38400/60000 (64%\tLoss:0.123582)]\n",
      "Train Epoch: 37 [51200/60000 (85%\tLoss:0.295556)]\n",
      "[37] Test Loss: 0.2849, Accuracy: 90.06%\n",
      "Train Epoch: 38 [0/60000 (0%\tLoss:0.282272)]\n",
      "Train Epoch: 38 [12800/60000 (21%\tLoss:0.317020)]\n",
      "Train Epoch: 38 [25600/60000 (43%\tLoss:0.231615)]\n",
      "Train Epoch: 38 [38400/60000 (64%\tLoss:0.266330)]\n",
      "Train Epoch: 38 [51200/60000 (85%\tLoss:0.282011)]\n",
      "[38] Test Loss: 0.2883, Accuracy: 89.91%\n",
      "Train Epoch: 39 [0/60000 (0%\tLoss:0.283959)]\n",
      "Train Epoch: 39 [12800/60000 (21%\tLoss:0.197364)]\n",
      "Train Epoch: 39 [25600/60000 (43%\tLoss:0.145453)]\n",
      "Train Epoch: 39 [38400/60000 (64%\tLoss:0.264954)]\n",
      "Train Epoch: 39 [51200/60000 (85%\tLoss:0.245956)]\n",
      "[39] Test Loss: 0.2885, Accuracy: 89.66%\n",
      "Train Epoch: 40 [0/60000 (0%\tLoss:0.194538)]\n",
      "Train Epoch: 40 [12800/60000 (21%\tLoss:0.311276)]\n",
      "Train Epoch: 40 [25600/60000 (43%\tLoss:0.195586)]\n",
      "Train Epoch: 40 [38400/60000 (64%\tLoss:0.288553)]\n",
      "Train Epoch: 40 [51200/60000 (85%\tLoss:0.221673)]\n",
      "[40] Test Loss: 0.2927, Accuracy: 89.64%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./data',\n",
    "                         train=True,\n",
    "                         download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                      transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                      ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./data',\n",
    "                         train=False,\n",
    "                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                      transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                      ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 지금 만드는 CNN 모델의 커널 크기는 5x5 이고 컨볼루션 계층은 2개\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320) # -1: 남은 차원 모두, 320: x가 가진 원소 개수\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "model = CNN().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%\\tLoss:{:.6f})]'.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            # 배치 오차를 계산\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            # 가장 높은값을 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet (residual network)\n",
    "- CNN을 응용한 모델\n",
    "- 이미지 천만장을 학습하여 15만 장으로 인식률을 겨루는 이미지넷 대회에서 2015년에 우승한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "[1] Test Loss: 1.3045, Accuracy: 53.36%\n",
      "[2] Test Loss: 1.2201, Accuracy: 58.65%\n",
      "[3] Test Loss: 1.1727, Accuracy: 62.45%\n",
      "[4] Test Loss: 1.0331, Accuracy: 66.25%\n",
      "[5] Test Loss: 0.8668, Accuracy: 70.59%\n",
      "[6] Test Loss: 0.9446, Accuracy: 70.56%\n",
      "[7] Test Loss: 0.8022, Accuracy: 72.39%\n",
      "[8] Test Loss: 0.7174, Accuracy: 75.28%\n",
      "[9] Test Loss: 0.7642, Accuracy: 73.71%\n",
      "[10] Test Loss: 0.7883, Accuracy: 73.79%\n",
      "[11] Test Loss: 1.0360, Accuracy: 67.52%\n",
      "[12] Test Loss: 0.9577, Accuracy: 69.33%\n",
      "[13] Test Loss: 0.7728, Accuracy: 74.27%\n",
      "[14] Test Loss: 0.9231, Accuracy: 72.13%\n",
      "[15] Test Loss: 0.7862, Accuracy: 74.14%\n",
      "[16] Test Loss: 0.7261, Accuracy: 76.45%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-07ad4c0f6ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mschedular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-07ad4c0f6ae8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-07ad4c0f6ae8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-07ad4c0f6ae8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Fashion MNIST 대신 CIFAR-10 데이터셋 사용\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data',\n",
    "                         train=True,\n",
    "                         download=True,\n",
    "                         transform=transforms.Compose([\n",
    "                             transforms.RandomCrop(32, padding=4),\n",
    "                             transforms.RandomHorizontalFlip(),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                  (0.5, 0.5, 0.5))\n",
    "                         ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data',\n",
    "                         train=False,\n",
    "                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                      transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                  (0.5, 0.5, 0.5))\n",
    "                                                      ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 드롭아웃은 학습 중 데이터 일부를 배제하여 간접적으로 과적합을 막는 방식이지만, 배치 정규화는 신경만 내부 데이터에 직접 영향을 주는 방식\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "        # nn.Sequential은 여러 모듈(nn.Module)을 하나의 모듈로 묶는 역할을 함\n",
    "        # 각 레이어를 데이터가 순차적으로 지나갈 때 사용하면 코드를 간결하게 만들 수 있음\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        \n",
    "    \n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks -1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    # 16채널을 받아 32 채널을 출력, 32채널을 받아 64 채널을 출력, 이렇게 증폭하는 역할을 하는 모듈은 shortcut 모듈을 따로 갖게 된다.\n",
    "    # shortcut 모듈은 이전 입력을 중간층에 더해주어 이미지의 맥락이 보존될 수 있도록 하는 역할을 한다\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "model = ResNet().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0005)\n",
    "schedular = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "print(model)\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            # 배치 오차를 계산\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            # 가장 높은값을 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    schedular.step()\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
